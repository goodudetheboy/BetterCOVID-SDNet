{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487b3034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8004cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(directory:str, batch_size:int, test_size:int, rand_num:int, worker:int):\n",
    "    '''\n",
    "        directory: the directory of processed directory with class folders inside\n",
    "        batch_size: size of batch for training\n",
    "        test_size: percent of dataset used for test\n",
    "        rand_num: put random number for reproducibility\n",
    "        worker: number of worker in computation\n",
    "        \n",
    "        return train and test data ready for training\n",
    "    '''\n",
    "    #pipeline to resize images, crop, convert to tensor, and normalize\n",
    "    trans = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    dataset = torchvision.datasets.ImageFolder(root=directory, transform=trans) #read image in folder to data with labels\n",
    "    \n",
    "    train_len = len(dataset) #get length of whole data\n",
    "    ind = list(range(train_len)) #indices of whole data\n",
    "    spl = int(np.floor(test_size * train_len)) #index of test data\n",
    "    \n",
    "    #reproducibility and shuffle step\n",
    "    np.random.seed(rand_num) \n",
    "    np.random.shuffle(ind)\n",
    "    \n",
    "    #sampling preparation steps\n",
    "    train_id, test_id = ind[spl:], ind[:spl]\n",
    "    tr_sampl = SubsetRandomSampler(train_id)\n",
    "    te_sampl = SubsetRandomSampler(test_id)\n",
    "\n",
    "    #use data loader to get train and test set ready for training\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=tr_sampl,num_workers=worker)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=te_sampl,num_workers=worker)\n",
    "    return (trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62057d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dire = \"./Data/Processed\" # directory of dataset\n",
    "# loading data loader\n",
    "trainloader, testloader = preprocess_data(directory=dire, batch_size=16, test_size=0.3, rand_num=40, worker=4)\n",
    "# getting device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "resnet101 = torchvision.models.resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7edcc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), AdaptiveAvgPool2d(output_size=(1, 1))]\n"
     ]
    }
   ],
   "source": [
    "resnet50 = torchvision.models.resnet50(pretrained=True)\n",
    "modules = list(resnet50.children())[:-1]\n",
    "print(modules)\n",
    "resnet50_model = nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d06cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4443a2457aa640638f6c4fd97836f4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[1/10], training loss: 3.1953\n",
      "Epoch:[2/10], training loss: 0.9174\n",
      "Epoch:[3/10], training loss: 0.3971\n",
      "Epoch:[4/10], training loss: 0.2122\n",
      "Epoch:[5/10], training loss: 0.1115\n",
      "Epoch:[6/10], training loss: 0.0409\n",
      "Epoch:[7/10], training loss: 0.0197\n",
      "Epoch:[8/10], training loss: 0.0236\n",
      "Epoch:[9/10], training loss: 0.0173\n",
      "Epoch:[10/10], training loss: 0.0156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c48100b370>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = resnet50\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = net.to(device)\n",
    "losses = []\n",
    "epochs = 10\n",
    "for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "# YOUR CODE HERE\n",
    "    Loss = 0.0\n",
    "    count = 0\n",
    "    for iter, data in enumerate(trainloader, 0):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        predicted = net(images)\n",
    "        _, pre1 = torch.max(predicted,dim=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(predicted, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        Loss += loss.item() #accumulate the loss\n",
    "        count += 1\n",
    "\n",
    "    avg_loss = Loss/count\n",
    "    losses.append(avg_loss) #append the average loss for each batch\n",
    "    print('Epoch:[{}/{}], training loss: {:.4f}'.format(epoch+1, epochs, avg_loss))\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "591a4d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.7020,  8.6863, 18.5866,  ..., -1.4888,  0.7603,  2.1930],\n",
      "        [ 5.8797,  5.6715, 18.9824,  ..., -2.2165, -0.6631,  3.1671],\n",
      "        [ 9.3582, 10.6726, 11.1576,  ..., -0.3798, -0.1606,  0.2513],\n",
      "        ...,\n",
      "        [ 9.6668, 15.4612, 11.0755,  ..., -0.2377,  2.3062, -0.0742],\n",
      "        [ 6.5263, 10.5423, 18.8167,  ..., -1.1789,  0.3268,  0.6900],\n",
      "        [ 9.7677,  8.6550, 15.7375,  ..., -1.1307,  0.8119,  1.6364]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 6.4883,  8.9786, 16.7473,  ..., -0.6835,  1.1350,  0.8391],\n",
      "        [11.1874, 12.6418, 10.1867,  ...,  1.5446,  1.1793,  1.6521],\n",
      "        [11.5479,  9.1854, 12.6125,  ..., -1.4003,  1.3933, -1.4129],\n",
      "        ...,\n",
      "        [11.5565, 11.3828, 10.7495,  ...,  0.4944, -0.1761,  1.2644],\n",
      "        [ 8.4296,  7.2832, 14.6160,  ..., -2.4768,  0.5173,  2.5158],\n",
      "        [ 5.4837,  8.3093, 17.3371,  ..., -1.6116,  1.5925,  1.6897]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 7.4164,  8.2898, 16.8488,  ...,  2.2534,  0.9188,  1.9070],\n",
      "        [ 8.1995,  7.4583, 17.0333,  ..., -1.3205,  0.5374, -0.5529],\n",
      "        [ 6.6329, 12.1242, 12.6545,  ..., -2.3523,  0.7245,  0.3678],\n",
      "        ...,\n",
      "        [13.6900, 11.2009, 11.0139,  ...,  1.0905,  0.8919,  1.1010],\n",
      "        [10.4210, 11.7328, 11.9197,  ..., -1.4755,  1.0578,  0.7665],\n",
      "        [11.3439, 11.2119, 13.5757,  ...,  0.1623, -0.0369,  0.1424]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 9.8253e+00,  9.8860e+00,  1.4483e+01,  ..., -2.7371e-01,\n",
      "          1.7375e+00, -3.6764e-01],\n",
      "        [ 1.0268e+01,  9.4349e+00,  1.5543e+01,  ...,  1.7968e+00,\n",
      "          4.2844e-01, -6.0266e-01],\n",
      "        [ 1.5092e+01,  1.1578e+01,  8.7980e+00,  ...,  9.1612e-02,\n",
      "         -6.0604e-01, -9.0012e-01],\n",
      "        ...,\n",
      "        [ 8.4060e+00,  1.1814e+01,  1.1800e+01,  ..., -1.9308e-03,\n",
      "          3.9788e+00,  1.3894e+00],\n",
      "        [ 8.0493e+00,  5.8730e+00,  1.6340e+01,  ..., -2.1235e+00,\n",
      "          6.9036e-01,  5.7926e-01],\n",
      "        [ 1.2586e+01,  1.6737e+01,  9.2640e+00,  ...,  1.8363e+00,\n",
      "          3.2626e+00,  4.7898e-02]], device='cuda:0')\n",
      "tensor([[ 8.1178,  9.9597, 11.2359,  ...,  2.3480,  0.7148,  1.0963],\n",
      "        [10.5586, 13.1470,  9.1881,  ..., -0.2669,  1.4984,  1.5433],\n",
      "        [11.0304, 14.7225, 10.4332,  ...,  0.4597,  2.4271, -0.0377],\n",
      "        ...,\n",
      "        [10.7284, 14.3870,  9.6666,  ...,  0.4761,  1.1722, -0.0863],\n",
      "        [ 9.4090,  7.3144, 13.7636,  ..., -0.6304,  0.1492,  0.6612],\n",
      "        [ 8.8854, 10.3273,  8.3890,  ...,  1.9240,  0.7153,  2.1305]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 8.1946, 14.0334, 11.0022,  ..., -0.0334,  1.5350, -0.0213],\n",
      "        [ 8.2161,  6.9153, 14.4731,  ...,  0.4023, -0.3240,  1.6257],\n",
      "        [ 9.9519, 17.2912, 10.7375,  ...,  0.2644,  5.0613, -0.7422],\n",
      "        ...,\n",
      "        [ 7.2425,  6.7726, 13.8702,  ...,  0.2278, -0.3693,  1.4038],\n",
      "        [10.0666,  8.4837, 13.2252,  ..., -0.8125,  0.7230,  1.4913],\n",
      "        [10.9991, 10.0258, 17.0963,  ..., -3.2209,  0.3770, -1.4728]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 9.5232e+00,  1.5669e+01,  9.7255e+00,  ...,  1.1508e+00,\n",
      "          2.1792e+00,  6.3238e-01],\n",
      "        [ 6.7501e+00,  5.4071e+00,  1.9793e+01,  ..., -2.0658e+00,\n",
      "         -3.9173e-01,  8.9568e-01],\n",
      "        [ 1.3662e+01,  9.1416e+00,  1.6357e+01,  ...,  9.7858e-01,\n",
      "         -1.6352e-01,  1.1177e+00],\n",
      "        ...,\n",
      "        [ 1.3650e+01,  1.1400e+01,  1.2134e+01,  ..., -5.5866e-01,\n",
      "         -2.9908e-01,  1.3857e-02],\n",
      "        [ 6.4721e+00,  1.0534e+01,  1.0844e+01,  ..., -9.8151e-01,\n",
      "          3.0604e+00,  1.7471e-01],\n",
      "        [ 9.8282e+00,  1.0462e+01,  1.0698e+01,  ..., -2.0136e+00,\n",
      "          2.0612e-01,  2.9665e-01]], device='cuda:0')\n",
      "tensor([[11.3418, 12.0738, 11.5486,  ...,  0.5348,  0.9244,  0.6926],\n",
      "        [11.8059, 15.9718,  8.1035,  ..., -1.8615,  2.7135,  0.7409],\n",
      "        [10.1990,  7.6646, 18.4723,  ..., -0.6943,  0.8284,  0.1549],\n",
      "        ...,\n",
      "        [ 6.7095, 12.5597, 10.4389,  ..., -0.4021,  2.3331, -0.2145],\n",
      "        [ 6.8205,  8.8088, 21.9168,  ..., -1.8255, -1.3130,  1.2445],\n",
      "        [ 8.9314, 10.9499, 10.3615,  ..., -1.7591,  1.4522,  1.1801]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 7.6662, 10.4479, 12.4327,  ..., -2.4031,  1.9339,  0.8740],\n",
      "        [ 9.4596, 11.7709, 14.0307,  ..., -1.0296,  0.1072,  1.4978],\n",
      "        [ 9.2158,  7.6871, 13.6947,  ..., -1.6785,  1.2647,  0.2649],\n",
      "        ...,\n",
      "        [ 6.3702,  9.0952, 15.7992,  ..., -0.9667,  1.2899,  1.4197],\n",
      "        [ 8.4818,  7.0719, 14.3395,  ..., -0.1829,  0.1256,  0.6958],\n",
      "        [10.7632,  8.6822, 16.2415,  ...,  2.5847,  0.3538,  1.2451]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 8.0758e+00,  5.3708e+00,  1.6458e+01,  ..., -1.3207e+00,\n",
      "          4.7590e-01,  5.3751e-01],\n",
      "        [ 1.0113e+01,  7.6232e+00,  1.4860e+01,  ..., -1.1069e+00,\n",
      "         -3.0529e-01, -2.8471e-01],\n",
      "        [ 1.1082e+01,  6.7016e+00,  1.9269e+01,  ..., -3.2266e-01,\n",
      "          1.2449e+00,  7.3352e-01],\n",
      "        ...,\n",
      "        [ 8.8014e+00,  1.1191e+01,  1.2560e+01,  ...,  1.4413e-01,\n",
      "          1.4214e+00, -1.3560e-02],\n",
      "        [ 7.9048e+00,  1.7091e+01,  8.4842e+00,  ..., -1.0856e+00,\n",
      "          2.5176e+00,  4.1085e-01],\n",
      "        [ 9.2226e+00,  1.0655e+01,  7.9086e+00,  ...,  1.0590e+00,\n",
      "          1.2332e+00, -4.0792e-01]], device='cuda:0')\n",
      "tensor([[ 7.0839,  4.9230, 19.7959,  ..., -3.0345, -0.0392,  4.0348],\n",
      "        [ 9.2941, 16.6126,  8.6140,  ..., -0.4388,  2.7539,  0.0803],\n",
      "        [14.3524,  9.4722, 12.5005,  ..., -0.0673,  1.5695, -0.5621],\n",
      "        ...,\n",
      "        [ 8.8450, 12.5910,  9.9919,  ..., -0.9465,  2.0280,  0.7924],\n",
      "        [10.5511, 12.1839,  6.3168,  ..., -0.1009,  1.8687, -0.3153],\n",
      "        [ 5.2816, 10.1872, 16.8389,  ..., -1.5713, -0.1661,  1.1392]],\n",
      "       device='cuda:0')\n",
      "tensor([[10.7042,  9.3184, 15.8019,  ...,  1.6387, -0.2536,  1.5706],\n",
      "        [12.8217, 15.3600,  9.1383,  ...,  2.2972,  2.5798, -1.1289],\n",
      "        [ 7.2889, 13.0402,  9.0846,  ..., -0.6537,  1.5286,  0.7881],\n",
      "        ...,\n",
      "        [11.9361, 18.5702,  8.1521,  ..., -0.4209,  2.3689, -0.2551],\n",
      "        [ 9.5306, 11.4799, 12.0325,  ..., -0.6145,  1.3011, -0.3810],\n",
      "        [11.5071,  9.2776, 15.0230,  ...,  1.9134,  1.8760, -0.6456]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 5.5218,  9.8879, 21.2655,  ..., -3.5142,  1.8318,  1.0450],\n",
      "        [10.0212, 13.1554,  9.2628,  ...,  0.5752,  2.2136,  0.9539],\n",
      "        [ 5.9637,  9.8652, 16.4145,  ..., -2.3054,  0.3644,  1.0564],\n",
      "        ...,\n",
      "        [12.7062,  9.8308, 15.4603,  ...,  2.1622,  1.8417,  0.3323],\n",
      "        [ 7.1580,  7.2875, 16.6348,  ..., -1.8598,  0.9229,  1.0375],\n",
      "        [ 7.5614,  9.5524, 14.6446,  ..., -1.9786, -0.3993,  0.4680]],\n",
      "       device='cuda:0')\n",
      "tensor([[10.4926, 11.0505, 14.3818,  ..., -0.8373,  0.4944,  1.1811],\n",
      "        [11.4902, 10.3311, 16.2545,  ...,  0.8068, -0.6250,  0.2557],\n",
      "        [ 7.6262, 12.1490, 13.4283,  ..., -0.7075,  1.0019,  1.0543],\n",
      "        ...,\n",
      "        [ 9.6394, 12.8328,  9.9547,  ...,  0.1062,  1.4915,  1.3404],\n",
      "        [ 6.6215,  8.2971, 19.9007,  ..., -2.0037,  1.2604,  0.8660],\n",
      "        [ 8.2769, 11.2074, 10.7373,  ..., -0.2816, -0.0986,  1.1643]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 8.1901e+00,  1.3191e+01,  1.1080e+01,  ...,  1.2361e+00,\n",
      "          2.3254e+00,  9.3277e-01],\n",
      "        [ 8.1803e+00,  7.2391e+00,  1.8374e+01,  ..., -6.8830e-01,\n",
      "          1.4077e-01,  3.0437e+00],\n",
      "        [ 9.7703e+00,  8.9300e+00,  1.5923e+01,  ..., -1.8360e-01,\n",
      "          4.3494e-02,  4.8564e-01],\n",
      "        ...,\n",
      "        [ 7.8051e+00,  7.1909e+00,  1.9868e+01,  ..., -1.8812e+00,\n",
      "         -3.8939e-01, -1.1906e-03],\n",
      "        [ 1.2080e+01,  8.3189e+00,  1.1527e+01,  ...,  1.7036e+00,\n",
      "          7.3692e-01,  7.7606e-01],\n",
      "        [ 1.0522e+01,  1.6602e+01,  6.1537e+00,  ...,  1.5103e+00,\n",
      "          2.9315e+00, -5.0682e-01]], device='cuda:0')\n",
      "tensor([[12.5699,  9.8126, 11.1243,  ...,  0.2749,  0.4754,  0.2782],\n",
      "        [ 7.9174,  7.8720, 18.5922,  ..., -2.4225, -0.7069,  2.0550],\n",
      "        [ 6.3875,  8.9026, 13.2776,  ...,  0.4718,  0.5227,  1.2098],\n",
      "        ...,\n",
      "        [ 7.5583, 13.8716, 10.6548,  ..., -1.8589,  0.6402,  1.0755],\n",
      "        [ 9.9031, 14.0640,  9.6948,  ..., -0.2038,  2.3805, -0.7491],\n",
      "        [15.2819, 10.2507,  9.8541,  ...,  1.3984, -0.0932, -2.0567]],\n",
      "       device='cuda:0')\n",
      "Accuracy of the network on the 10000 validation x: 61 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_hat = net(images)\n",
    "        max_val, max_i = torch.max(y_hat.data, 1)\n",
    "        print(y_hat)\n",
    "        total += labels.size(0)\n",
    "        correct += (max_i == labels).sum().item()\n",
    "        \n",
    "print(f'Accuracy of the network on the 10000 validation x: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
