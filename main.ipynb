{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487b3034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8004cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(directory:str, batch_size:int, test_size:int, rand_num:int, worker:int):\n",
    "    '''\n",
    "        directory: the directory of processed directory with class folders inside\n",
    "        batch_size: size of batch for training\n",
    "        test_size: percent of dataset used for test\n",
    "        rand_num: put random number for reproducibility\n",
    "        worker: number of worker in computation\n",
    "        \n",
    "        return train and test data ready for training\n",
    "    '''\n",
    "    #pipeline to resize images, crop, convert to tensor, and normalize\n",
    "    trans = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    dataset = torchvision.datasets.ImageFolder(root=directory, transform=trans) #read image in folder to data with labels\n",
    "    \n",
    "    train_len = len(dataset) #get length of whole data\n",
    "    ind = list(range(train_len)) #indices of whole data\n",
    "    spl = int(np.floor(test_size * train_len)) #index of test data\n",
    "    \n",
    "    #reproducibility and shuffle step\n",
    "    np.random.seed(rand_num) \n",
    "    np.random.shuffle(ind)\n",
    "    \n",
    "    #sampling preparation steps\n",
    "    train_id, test_id = ind[spl:], ind[:spl]\n",
    "    tr_sampl = SubsetRandomSampler(train_id)\n",
    "    te_sampl = SubsetRandomSampler(test_id)\n",
    "\n",
    "    #use data loader to get train and test set ready for training\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=tr_sampl,num_workers=worker)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=te_sampl,num_workers=worker)\n",
    "    return (trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e62057d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dire = \"./Data/Processed\"\n",
    "trainloader, testloader = preprocess_data(\n",
    "                                        directory=dire,\n",
    "                                        batch_size=4,\n",
    "                                        test_size=0.3,\n",
    "                                        rand_num=40,\n",
    "                                        worker=4\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d06cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "net = Net()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = net.cuda()\n",
    "temp = []\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "# YOUR CODE HERE\n",
    "    a = 0.0\n",
    "    for j, data in enumerate(trainloader, 0):\n",
    "        inp, out = data #take input and output from a batch from train data\n",
    "        inp = inp.cuda() #make input to GPU\n",
    "        out = out.cuda() #make output to GPU\n",
    "        optimizer.zero_grad() #zero out the gradients\n",
    "        pre = net(inp) #make prediction with model\n",
    "        _,pre1 = torch.max(pre,dim=1) #use the class with highest predicted probability\n",
    "        loss = criterion(pre, out) #calculate the loss\n",
    "        loss.backward() #do backpropagation step\n",
    "        optimizer.step() #use optimizer for backpropagation step\n",
    "        a += loss.item() #accumulate the loss\n",
    "    temp.append(a/(j+1)) #append the average loss for each batch\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
