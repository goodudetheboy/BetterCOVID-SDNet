{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487b3034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8004cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(directory:str, batch_size:int, test_size:int, rand_num:int, worker:int):\n",
    "    '''\n",
    "        directory: the directory of processed directory with class folders inside\n",
    "        batch_size: size of batch for training\n",
    "        test_size: percent of dataset used for test\n",
    "        rand_num: put random number for reproducibility\n",
    "        worker: number of worker in computation\n",
    "        \n",
    "        return train and test data ready for training\n",
    "    '''\n",
    "    #pipeline to resize images, crop, convert to tensor, and normalize\n",
    "    trans = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    dataset = torchvision.datasets.ImageFolder(root=directory, transform=trans) #read image in folder to data with labels\n",
    "    \n",
    "    train_len = len(dataset) #get length of whole data\n",
    "    ind = list(range(train_len)) #indices of whole data\n",
    "    spl = int(np.floor(test_size * train_len)) #index of test data\n",
    "    \n",
    "    #reproducibility and shuffle step\n",
    "    np.random.seed(rand_num) \n",
    "    np.random.shuffle(ind)\n",
    "    \n",
    "    #sampling preparation steps\n",
    "    train_id, test_id = ind[spl:], ind[:spl]\n",
    "    tr_sampl = SubsetRandomSampler(train_id)\n",
    "    te_sampl = SubsetRandomSampler(test_id)\n",
    "\n",
    "    #use data loader to get train and test set ready for training\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=tr_sampl,num_workers=worker)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=te_sampl,num_workers=worker)\n",
    "    return (trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609e2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_layer(pretrained: nn.Module, num_class: int) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "        pretrained : np.array\n",
    "            A pretrained model\n",
    "        num_class : int\n",
    "            The number of classes the classification problem requires.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        The input pretrained model, but with the last fc layer have the num_class instead\n",
    "    \"\"\"\n",
    "\n",
    "    pretrained.fc = nn.Linear(pretrained.fc.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62057d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dire = \"./Data/Processed\" # directory of dataset\n",
    "# loading data loader\n",
    "trainloader, testloader = preprocess_data(directory=dire, batch_size=16, test_size=0.3, rand_num=40, worker=4)\n",
    "# getting device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73dd0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16\n",
    "vgg16 = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7edcc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = torchvision.models.resnet50(pretrained=True)\n",
    "modules = list(resnet50.children())\n",
    "resnet50.fc = nn.Linear(2048,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2d06cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5475a1e71674935af4400739edd6b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[1/50], training loss: 1.3398\n",
      "Epoch:[2/50], training loss: 1.0384\n",
      "Epoch:[3/50], training loss: 0.7239\n",
      "Epoch:[4/50], training loss: 0.4682\n",
      "Epoch:[5/50], training loss: 0.3118\n",
      "Epoch:[6/50], training loss: 0.1780\n",
      "Epoch:[7/50], training loss: 0.1160\n",
      "Epoch:[8/50], training loss: 0.0815\n",
      "Epoch:[9/50], training loss: 0.0705\n",
      "Epoch:[10/50], training loss: 0.1555\n",
      "Epoch:[11/50], training loss: 0.0682\n",
      "Epoch:[12/50], training loss: 0.1089\n",
      "Epoch:[13/50], training loss: 0.0753\n",
      "Epoch:[14/50], training loss: 0.0661\n",
      "Epoch:[15/50], training loss: 0.1041\n",
      "Epoch:[16/50], training loss: 0.1531\n",
      "Epoch:[17/50], training loss: 0.0639\n",
      "Epoch:[18/50], training loss: 0.0341\n",
      "Epoch:[19/50], training loss: 0.0192\n",
      "Epoch:[20/50], training loss: 0.0191\n",
      "Epoch:[21/50], training loss: 0.0119\n",
      "Epoch:[22/50], training loss: 0.0172\n",
      "Epoch:[23/50], training loss: 0.0241\n",
      "Epoch:[24/50], training loss: 0.0573\n",
      "Epoch:[25/50], training loss: 0.0345\n",
      "Epoch:[26/50], training loss: 0.0370\n",
      "Epoch:[27/50], training loss: 0.0272\n",
      "Epoch:[28/50], training loss: 0.0280\n",
      "Epoch:[29/50], training loss: 0.0395\n",
      "Epoch:[30/50], training loss: 0.0204\n",
      "Epoch:[31/50], training loss: 0.0196\n",
      "Epoch:[32/50], training loss: 0.0329\n",
      "Epoch:[33/50], training loss: 0.0383\n",
      "Epoch:[34/50], training loss: 0.0436\n",
      "Epoch:[35/50], training loss: 0.0552\n",
      "Epoch:[36/50], training loss: 0.0219\n",
      "Epoch:[37/50], training loss: 0.0138\n",
      "Epoch:[38/50], training loss: 0.0131\n",
      "Epoch:[39/50], training loss: 0.0151\n",
      "Epoch:[40/50], training loss: 0.0139\n",
      "Epoch:[41/50], training loss: 0.0067\n",
      "Epoch:[42/50], training loss: 0.0042\n",
      "Epoch:[43/50], training loss: 0.0098\n",
      "Epoch:[44/50], training loss: 0.0096\n",
      "Epoch:[45/50], training loss: 0.0147\n",
      "Epoch:[46/50], training loss: 0.0156\n",
      "Epoch:[47/50], training loss: 0.0054\n",
      "Epoch:[48/50], training loss: 0.0050\n",
      "Epoch:[49/50], training loss: 0.0057\n",
      "Epoch:[50/50], training loss: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28e3cd17fa0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#net = resnet50\n",
    "from ipywidgets import IntProgress\n",
    "net = resnet50\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = net.to(device)\n",
    "losses = []\n",
    "epochs = 50\n",
    "for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "# YOUR CODE HERE\n",
    "    Loss = 0.0\n",
    "    count = 0\n",
    "    for iter, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        predicted = net(images)\n",
    "        _, pre1 = torch.max(predicted,dim=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(predicted, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        Loss += loss.item() #accumulate the loss\n",
    "        count += 1\n",
    "\n",
    "    avg_loss = Loss/count\n",
    "    losses.append(avg_loss) #append the average loss for each batch\n",
    "    print('Epoch:[{}/{}], training loss: {:.4f}'.format(epoch+1, epochs, avg_loss))\n",
    "\n",
    "    # validation\n",
    "    if epoch%5==0:\n",
    "        Loss = 0\n",
    "        plt.figure(figsize=(10,4))\n",
    "        with torch.no_grad():\n",
    "            for iter, data in enumerate(testloader):\n",
    "                images, labels = data\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                predicted = net(images)\n",
    "                _, pre1 = torch.max(predicted,dim=1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(predicted, labels)\n",
    "\n",
    "                Loss += loss.item() #accumulate the loss\n",
    "                count += 1\n",
    "        print('Epoch:[{}/{}], validation loss: {:.4f}'.format(i+1, epochs, Loss))\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "591a4d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 validation x: 57 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_hat = net(images)\n",
    "        max_val, max_i = torch.max(y_hat.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (max_i == labels).sum().item()\n",
    "        \n",
    "print(f'Accuracy of the network on the 10000 validation x: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
