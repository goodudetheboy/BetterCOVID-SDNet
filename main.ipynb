{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487b3034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8004cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(directory:str, batch_size:int, test_size:int, rand_num:int, worker:int):\n",
    "    '''\n",
    "        directory: the directory of processed directory with class folders inside\n",
    "        batch_size: size of batch for training\n",
    "        test_size: percent of dataset used for test\n",
    "        rand_num: put random number for reproducibility\n",
    "        worker: number of worker in computation\n",
    "        \n",
    "        return train and test data ready for training\n",
    "    '''\n",
    "    #pipeline to resize images, crop, convert to tensor, and normalize\n",
    "    trans = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    dataset = torchvision.datasets.ImageFolder(root=directory, transform=trans) #read image in folder to data with labels\n",
    "    \n",
    "    train_len = len(dataset) #get length of whole data\n",
    "    ind = list(range(train_len)) #indices of whole data\n",
    "    spl = int(np.floor(test_size * train_len)) #index of test data\n",
    "    \n",
    "    #reproducibility and shuffle step\n",
    "    np.random.seed(rand_num) \n",
    "    np.random.shuffle(ind)\n",
    "    \n",
    "    #sampling preparation steps\n",
    "    train_id, test_id = ind[spl:], ind[:spl]\n",
    "    tr_sampl = SubsetRandomSampler(train_id)\n",
    "    te_sampl = SubsetRandomSampler(test_id)\n",
    "\n",
    "    #use data loader to get train and test set ready for training\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=tr_sampl,num_workers=worker)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=te_sampl,num_workers=worker)\n",
    "    return (trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a23417b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dire = \"./Data/Processed\" # directory of dataset\n",
    "# loading data loader\n",
    "trainloader, testloader = preprocess_data(directory=dire, batch_size=16, test_size=0.3, rand_num=40, worker=4)\n",
    "# getting device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7edcc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "# vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "# googlenet = torchvision.models.googlenet(pretrained=True)\n",
    "# efficientnet_b7 = torchvision.models.efficientnet_b7(pretrained=True)\n",
    "resnet50 = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7eff120",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierNet(nn.Module):\n",
    "    def __init__(self, pretrained: nn.Module):\n",
    "        super().__init__()\n",
    "        # Pretrained\n",
    "        self.network = pretrained\n",
    "        # Replace last layer\n",
    "        self.network.fc = nn.Sequential(nn.Linear(2048, 512), \n",
    "                                         nn.ReLU(),  \n",
    "                                         nn.Dropout(0.25),\n",
    "                                         nn.Linear(512, 128), \n",
    "                                         nn.ReLU(),  \n",
    "                                         nn.Dropout(0.50), \n",
    "                                         nn.Linear(128, 5)\n",
    "                                        )\n",
    "    def forward(self, x):\n",
    "        out = self.network(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb12db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def testAccuracy() -> int:\n",
    "    \n",
    "    net.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for iter, data in enumerate(testloader):\n",
    "            images, labels = data\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = net(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d06cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9201edb6ec5d4533b3066a526d1cb859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[1/50], training loss: 1.4364\n",
      "Accuracy of the network on the 10000 validation x: 52 %\n",
      "Epoch:[2/50], training loss: 1.3813\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23908/1127380012.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mLoss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#accumulate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ipywidgets import IntProgress\n",
    "#Command out all except one of the below\n",
    "#net = resnet50\n",
    "#net = vgg16\n",
    "#net = googlenet\n",
    "net = ClassifierNet(resnet50)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = net.to(device)\n",
    "losses = []\n",
    "epochs = 50\n",
    "for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "# YOUR CODE HERE\n",
    "    Loss = 0.0\n",
    "    count = 0\n",
    "    for iter, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        predicted = net(images)\n",
    "        _, pre1 = torch.max(predicted,dim=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(predicted, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        Loss += loss.item() #accumulate the loss\n",
    "        count += 1\n",
    "\n",
    "    avg_loss = Loss/count\n",
    "    losses.append(avg_loss) #append the average loss for each batch\n",
    "    print('Epoch:[{}/{}], training loss: {:.4f}'.format(epoch+1, epochs, avg_loss))\n",
    "\n",
    "    # validation\n",
    "    if epoch%5==0:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                y_hat = net(images)\n",
    "                max_val, max_i = torch.max(y_hat.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (max_i == labels).sum().item()\n",
    "        \n",
    "        print(f'Accuracy of the network on the 10000 validation x: {100 * correct // total} %')\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a4d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 validation x: 60 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_hat = net(images)\n",
    "        max_val, max_i = torch.max(y_hat.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (max_i == labels).sum().item()\n",
    "        \n",
    "print(f'Accuracy of the network on the 10000 validation x: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d282fbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
